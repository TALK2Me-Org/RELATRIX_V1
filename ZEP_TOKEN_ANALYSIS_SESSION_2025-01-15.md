# Analiza Eksplozji TokenÃ³w w Zep - Sesja 2025-01-15

## ğŸ” Problem: Eksplozja tokenÃ³w w Zep

### Objawy:
- Nowa sesja: ~200 tokenÃ³w âœ…
- Po zaÅ‚adowaniu starej sesji: 800+ tokenÃ³w âŒ
- Po 21 wiadomoÅ›ciach: 47,700 tokenÃ³w (vs 11,700 w Mem0)

### PrzykÅ‚ad z logÃ³w OpenAI (Zep):
```
Input:
system: You are the Relationship Upgrader, focused on taking good relationships to great ones...
User context and facts:
FACTS and ENTITIES represent relevant context to the current conversation.
# These are the most relevant facts and their valid date ranges
# format: FACT (Date range: from - to)
<FACTS>
- diamond da62 to naprawde fajna 2 silnikowa maszyna (2025-07-15 00:41:14 - present)
- ai (assistant) asked about the user's impressions from testing Diamond DA62 (2025-07-15 00:39:14 - 2025-07-15 00:41:14)
- ai (assistant) describes diamond da62 as a twin-engine design providing safety and comfort during flight (2025-07-15 00:41:14 - present)
- playground_user_1752539929106 ostatnio testowaÅ‚ diamond da62 (2025-07-15 00:39:14 - present)
[... 19 faktÃ³w total ...]
</FACTS>

# These are the most relevant entities
# ENTITY_NAME: entity summary
<ENTITIES>
- playground_user_1752539929106: UÅ¼ytkownik o ID playground_user_1752539929106 jest rolÄ… human...
- diamond da62: The entity 'diamond da62' was mentioned in a message...
- ai (assistant): The entity is an AI assistant named 'ai (assistant)'...
[... 8 encji total ...]
</ENTITIES>

user: myslalem ze pamietasz moje imie
```

## ğŸ“Š Analiza tokenÃ³w

### PorÃ³wnanie Zep vs Mem0:
- **Zep context**: ~1200-1400 tokenÃ³w (19 faktÃ³w + 8 encji z dÅ‚ugimi opisami)
- **Mem0 memories**: ~350-400 tokenÃ³w (5 krÃ³tkich wspomnieÅ„)
- **RÃ³Å¼nica**: ~1000 tokenÃ³w wiÄ™cej w Zep!

### PorÃ³wnanie po 21 wiadomoÅ›ciach:
| System | Input Tokens | Stosunek |
|--------|--------------|----------|
| **Zep** | 47,700 | 4x wiÄ™cej niÅ¼ Mem0! |
| **Mem0** | 11,700 | Baseline |
| **Full Context** | 64,600 | 5.5x wiÄ™cej niÅ¼ Mem0 |

## ğŸ§© Jak dziaÅ‚a Zep

### Zep automatycznie buduje graf wiedzy:
1. Ekstraktuje fakty z kaÅ¼dej wiadomoÅ›ci
2. Tworzy encje (osoby, miejsca, rzeczy)
3. Dodaje timestamps do wszystkiego
4. Kumuluje wszystko w `memories.context`

### Nasz kod (playground_zep.py):
```python
# Pobieramy memories
memories = await zep_client.memory.get(session_id=session_id)

# Dodajemy context do system prompt
if memories and memories.context:
    system_content += f"\n\nUser context and facts:\n{memories.context}"

# WysyÅ‚amy do OpenAI tylko 2 wiadomoÅ›ci
messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": message}
]
```

### Problem: Context roÅ›nie z kaÅ¼dÄ… wiadomoÅ›ciÄ…!
- Po 1 wiadomoÅ›ci: kilka faktÃ³w
- Po 10 wiadomoÅ›ciach: dziesiÄ…tki faktÃ³w + rozbudowane encje
- Po 20 wiadomoÅ›ciach: setki faktÃ³w = eksplozja tokenÃ³w

## ğŸ’¡ RozwiÄ…zania omawiane

### 1. Smart Context z graph.search() (REKOMENDOWANE)
```python
# Zamiast memory.get() ktÃ³ry zwraca wszystko
# UÅ¼ywamy targeted search
facts_results = await zep_client.graph.search(
    user_id=user_id,
    query=message,  # bieÅ¼Ä…ca wiadomoÅ›Ä‡ jako query
    limit=5,        # tylko 5 najwaÅ¼niejszych faktÃ³w
    search_type="edge",
    reranker="mmr"  # dla rÃ³Å¼norodnoÅ›ci
)

# Budujemy maÅ‚y, relevant context (200-500 tokenÃ³w zamiast 2000)
```

### 2. Function Calling - Zep jako Tool
```python
tools = [{
    "type": "function",
    "function": {
        "name": "search_user_memory",
        "description": "Search for information from previous conversations",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string"}
            }
        }
    }
}]

# Model sam decyduje kiedy potrzebuje pamiÄ™ci
# 80% przypadkÃ³w: nie wywoÅ‚uje = szybsze i taÅ„sze
# 20% przypadkÃ³w: wywoÅ‚uje = podobny czas jak teraz
```

#### PrzykÅ‚ad flow z Function Calling:
1. User: "PamiÄ™tasz jak mam na imiÄ™?"
2. Model: WywoÅ‚uje `search_user_memory("user name")`
3. My: Wykonujemy search w Zep
4. Zep: "User's name is RafaÅ‚"
5. Model: "Tak, masz na imiÄ™ RafaÅ‚!"

### 3. Przycinanie context (najprostsze)
```python
if memories and memories.context:
    context = memories.context
    if len(context) > 1000:
        context = context[:1000] + "\n[...context truncated...]"
    system_content += f"\n\n=== CONDENSED HISTORY ===\n{context}\n=== END ===\n"
```

### 4. WyÅ‚Ä…czenie context caÅ‚kowicie
```python
# ZakomentowaÄ‡:
# if memories and memories.context:
#     system_content += f"\n\nUser context and facts:\n{memories.context}"
```

## ğŸ“š Dokumentacja Zep API

### memory.get()
- Zwraca: `context` (string z faktami/encjami), `messages`, `facts`
- Brak parametrÃ³w kontroli wielkoÅ›ci
- Automatycznie decyduje co jest "relevant"

### graph.search() (bardziej elastyczne)
```python
results = await zep_client.graph.search(
    user_id=user_id,
    query="diamond da62",  
    limit=5,              # kontrola iloÅ›ci
    search_type="edge",   # lub "node" dla encji
    reranker="mmr"        # rÃ³Å¼ne algorytmy rankingu
)
```

### Typy rerankerÃ³w:
- `rrf` (default) - Reciprocal Rank Fusion
- `mmr` - Maximum Marginal Relevance (dla rÃ³Å¼norodnoÅ›ci)
- `cross_encoder` - dokÅ‚adniejsze scorowanie

## ğŸ› Odkryty bug w Mem0

### Problem:
Playground_mem0.py wysyÅ‚aÅ‚ do Mem0 caÅ‚e messages wÅ‚Ä…cznie z system prompt:
```python
# BYÅO:
messages = [
    {"role": "system", "content": system_prompt + memory_context},
    {"role": "user", "content": message}
]
messages.append({"role": "assistant", "content": full_response})
await add_memory(messages, user_id)  # âŒ System prompt teÅ¼ leciaÅ‚!
```

### Naprawiono:
```python
# JEST:
await add_memory([
    {"role": "user", "content": message},
    {"role": "assistant", "content": full_response}
], user_id)  # âœ… Tylko konwersacja!
```

## ğŸ¯ Wnioski

### Zep vs Mem0:
- **Zep**: PotÄ™Å¼ny graf wiedzy, ale drogi (4x wiÄ™cej tokenÃ³w)
- **Mem0**: Prostsze wspomnienia, taÅ„sze
- **Trade-off**: JakoÅ›Ä‡ vs Koszty

### Zalety Zep:
- Model "wie praktycznie wszystko"
- Fakty sÄ… datowane
- Automatyczna ekstrakcja encji
- Åšwietne dla zÅ‚oÅ¼onych, dÅ‚ugich konwersacji

### Wady Zep:
- 1500-2000 tokenÃ³w per wiadomoÅ›Ä‡
- Brak kontroli wielkoÅ›ci context
- MoÅ¼e przekroczyÄ‡ limity przy dÅ‚ugich sesjach

## ğŸ“ Do zrobienia:

1. **Implementacja Smart Context** z graph.search()
2. **Debugowanie** - dodaÄ‡ logi wielkoÅ›ci context
3. **Testing Function Calling** jako alternatywa
4. **NaprawiÄ‡ liczenie tokenÃ³w** - zmieniÄ‡ `str(msg)` na `msg['content']`
5. **UI feedback** - zmieniÄ‡ ikonÄ™ w SessionsTab.tsx

## ğŸ”— Linki i zasoby:
- https://help.getzep.com/concepts#memory-context
- https://help.getzep.com/searching-the-graph
- Zep graph API dla wiÄ™kszej kontroli

## ğŸ’­ PrzemyÅ›lenia:
- Zep jest zaprojektowany do automatycznego zarzÄ…dzania kontekstem
- W niektÃ³rych przypadkach to za duÅ¼o automatyzacji
- Function Calling moÅ¼e byÄ‡ najlepszym kompromisem
- Warto monitorowaÄ‡ koszty przy produkcyjnym uÅ¼yciu

## ğŸ£ PrzykÅ‚ad rozmowy - Marek i ryby (5 wiadomoÅ›ci)

### Przebieg:
1. User: "witam :)"
2. User: "bylem na rybach z januszem a nazwyam sie Marek"
3. User: "zlowilismy fajnego karpia nad jeziorem kierskim niedaleko poznania"
4. User: "to byla wspaniala chwila, a smieszne bylo to ze zabraklo nam benzyny w naszej Å‚odzi i znajomy Lukasz przywiozl nam kajakiem paliwo:))))"
5. User: "troche nam sie wylalo podczas tankowania ale to chyba nie powinno zaszkodzic rybka w jeziorze?"

### Co Zep wygenerowaÅ‚:

#### FAKTY (7 faktÃ³w z duplikacjami):
- Åukasz przywiozl paliwo kajakiem dla Marka, gdy zabraklo benzyny w lodzi
- Paliwo do Å‚Ã³dki zostaÅ‚o dostarczone kajakiem (DUPLIKAT!)
- Marek byÅ‚ na rybach z Januszem
- jezioro kierskie jest niedaleko Poznania
- Janusz i karp nad jeziorem Kierskim
- Marek is a duplicate of playground_user_1752550332860
- karp zostaÅ‚ zÅ‚owiony nad jeziorem kierskim

#### ENCJE (7 encji - kaÅ¼da powtarza caÅ‚Ä… historiÄ™!):
- **Marek**: peÅ‚ny opis caÅ‚ej wyprawy
- **jezioro**: znowu caÅ‚a historia
- **playground_user_1752550332860**: znowu Marek
- **karp**: znowu caÅ‚a historia z rÃ³Å¼nych perspektyw
- **jezioro kierskie**: osobna encja dla tego samego jeziora!
- **Janusz**: osobna encja
- **PoznaÅ„**: znowu caÅ‚a historia

### Analiza duplikacji:
- Ta sama informacja (Marek, Janusz, ryby, jezioro, brak benzyny, Åukasz) powtÃ³rzona 7-8 razy!
- ~1500 tokenÃ³w dla 5 prostych wiadomoÅ›ci
- Gdyby rozmowa trwaÅ‚a 20 wiadomoÅ›ci, byÅ‚oby to 6000+ tokenÃ³w samego contextu

### Wnioski:
- Zep generuje masywne duplikacje
- KaÅ¼da encja zawiera peÅ‚nÄ… historiÄ™
- Brak deduplikacji informacji
- To wyjaÅ›nia eksplozjÄ™ tokenÃ³w